---
title: "Classification"
format: 
  revealjs:
    scrollable: true
    code-fold: true
    echo: true
    eval: true
editor_options: 
  chunk_output_type: console
---

## Classifying based on similarities with *k*-nearest neighbours.

- The *k*-nearest neighbour algorithm uses labeled data and therefore it is a supervised learning algorithm.
- How does the kNN learn?
  - Examples of snakes in UK 
  - Two species of venomous snakes- grass snake and adder.
  - Slow worm - a limbless reptile mistaken for a snake.
- Objective: Build a kNN classifier to help you quickly classify future specimens you come across.

---

- **Figure 3.1** Body length and aggression of reptiles. 

![](5.Classification_files/fig3.1.png)


---

- The *two* phases of the kNN algorithm;
  1. The training phase: In this phase the algorithm stores the data.
  2. The prediction phase: In this phase the kNN algorithm calculates the distance between each new, unlabeled case and all the labeled cases. *The term <u> distance </u> indicates the nearness in terms of body-weight and aggression.*
- The distance metric is often called the **Euclidean distance** (a straight-line distance between two points on a plot).

---

- **Figure 3.2** The first step of kNN algorithm: calculating distance.

![](5.Classification_files/fig3.2.png)

---

- Next, for each unlabeled case, the algorithm ranks the neighbours from the nearest (most similar) to the furthest (the least similar).
- **Figure 3.3** The second step of the kNN algorithm: ranking the neighbours.

![](5.Classification_files/fig3.3.png)


---

- The algorithm identifies *k*-labelled cases nearest to unlabeled cases.
- The *k*-labeled cases are most similar in-terms of the variables to the unlabeled case.
- Whatever class most of the *k*-nearest neighbours belong to is what the unlabeled case is classified as.

---

- **Figure 3.4** The final step: Identifying the *k*-nearest neighbours and taking the majority vote.

![](5.Classification_files/fig3.4.JPG)


## Building your first kNN model.
- You are trying to improve the diagnosis of patients with diabetes.
- You collect data and record if they were diagnosed as *healthy*, *chemically diabetic* or *overtly diabetic*.
- You want to use a kNN algorithm to train a model that can predict which of these classes a new patient will belong to so that diagnoses can be improved.
- This is a **three class classification** problem.

---

- Lets look at the diabetes data
```{r}
# required packages
library(mclust)
library(tidyverse)
library(mlr)

# the dataset
data(diabetes, package = 'mclust')
(as_tibble(diabetes) -> diabetes)
```

- The `class` shows three cases of diabetes - Normal, Chemical, and Overt.
- `glucose`: the level of blood glucose.
- `insulin`: the level of insulin 
- `sspg`: steady state level of blood glucose.

---

- The relationship between the variables are plotted below:


```{r}
diabetes %>% 
  ggplot(aes(glucose, insulin))+
  geom_point(aes(col = class))
```


```{r}
diabetes %>% 
  ggplot(aes(sspg, insulin))+
  geom_point(aes(col = class))
```

```{r}
diabetes %>% 
  ggplot(aes(sspg, glucose))+
  geom_point(aes(col = class))
```

---

**Exercise 1**

Reproduce the plot of glucose versus insulin, but use shapes rather than colors to indicate which class each case belongs to. Once youâ€™ve done this, modify your code to represent the classes using shape and color.

---

- From the data (scatter plots too) we can see that there are differences in the continuous variables among the three classes.
- So let's build a kNN classifier that can **predict diabetes status from measurements of future patients**.
- It is important to **scale** the predictor variables by dividing them by their standard deviation. 
  - This preserves the relationship between the variables.
  - This ensures that variables measured on larger scales are not given more importance by the algorithm.
- In our case, the `mlr` package can take care of the **scaling** of the varaibles as it is in the algorithm.


## Using `mlr` to train the kNN model
- The three stages in `mlr` package:
  1. **Define the task**: Classify the data with the `class` variable as the target variable.
  2. **Define the learner**: The learner is the name of the algorithm that we want to use.
  3. **Train the model**: After the learner generates the model, use it to make future predictions.
  
## 1. Defining the task.

- The components needed to define a task are:
  - Data containing the predictor variables
  - The target variable we want to predict.
