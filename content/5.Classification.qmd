---
title: "Classification"
format: 
  revealjs:
    scrollable: true
    code-fold: true
    echo: true
    eval: true
editor_options: 
  chunk_output_type: console
---

## Classifying based on similarities with *k*-nearest neighbours.

- The *k*-nearest neighbour algorithm uses labeled data and therefore it is a supervised learning algorithm.
- How does the kNN learn?
  - Examples of snakes in UK 
  - Two species of venomous snakes- grass snake and adder.
  - Slow worm - a limbless reptile mistaken for a snake.
- Objective: Build a kNN classifier to help you quickly classify future specimens you come across.

---

- **Figure 3.1** Body length and aggression of reptiles. 

![](5.Classification_files/fig3.1.png)


---

- The *two* phases of the kNN algorithm;
  1. The training phase: In this phase the algorithm stores the data.
  2. The prediction phase: In this phase the kNN algorithm calculates the distance between each new, unlabeled case and all the labeled cases. *The term <u> distance </u> indicates the nearness in terms of body-weight and aggression.*
- The distance metric is often called the **Euclidean distance** (a straight-line distance between two points on a plot).

---

- **Figure 3.2** The first step of kNN algorithm: calculating distance.

![](5.Classification_files/fig3.2.png)

---

- Next, for each unlabeled case, the algorithm ranks the neighbours from the nearest (most similar) to the furthest (the least similar).
- **Figure 3.3** The second step of the kNN algorithm: ranking the neighbours.

![](5.Classification_files/fig3.3.png)


---

- The algorithm identifies *k*-labelled cases nearest to unlabeled cases.
- The *k*-labeled cases are most similar in-terms of the variables to the unlabeled case.
- Whatever class most of the *k*-nearest neighbours belong to is what the unlabeled case is classified as.

---

- **Figure 3.4** The final step: Identifying the *k*-nearest neighbours and taking the majority vote.

![](5.Classification_files/fig3.4.JPG)


